{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8R2LyKrW0dLtphwvtzJpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Exar2004/fatec_PLN_Codes/blob/main/Aula_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQmZfvcA5Iio",
        "outputId": "64870140-eadd-4715-b731-1ee52bb7161a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'hugs'], 'negativo'), (['amo', 'resolver', 'problemas'], 'positive'), (['odeio', 'erras'], 'negativo')]\n",
            "Texto: \"Eu amo resolver bugs\"\n",
            "Classe prevista: positivo\n",
            "Probabilidades:\n",
            " positivo: 0.3333333333333333\n",
            " negativo: 0.25\n",
            " positive: 0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "#Passe 1 Criar o Corpus\n",
        "corpus = [\n",
        "(\"Eu amo PLN\", \"positivo\"),\n",
        "(\"Eu odeio hugs\", \"negativo\"),\n",
        "(\"Amo resolver problemas\", \"positive\"),\n",
        "(\"Odeio erras\", \"negativo\")\n",
        "]\n",
        "# Passo 2 -Processar o Texto\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "  return re.findall(r'\\b\\w+\\b',text.lower())\n",
        "\n",
        "processed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(processed_corpus)\n",
        "\n",
        "# Passo 3 - Calculando probabilidades\n",
        "class_counts = Counter() #contages das classes\n",
        "word_counts = defaultdict(Counter)\n",
        "total_words = defaultdict(int)\n",
        "\n",
        "for words, label in processed_corpus:\n",
        "  class_counts [label] += 1\n",
        "  for word in words:\n",
        "    word_counts [label][word] = 1\n",
        "    total_words[label]\n",
        "\n",
        "total_examples =  sum(class_counts.values())\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}\n",
        "def conditional_probability(word, label, alpha=1):\n",
        "  return(word_counts [label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))\n",
        "\n",
        "#Passo 4 Classificar um novo Texto\n",
        "def predict(text):\n",
        "  words = preprocess_text(text)\n",
        "  probabilities = {}\n",
        "\n",
        "  for label in class_counts.keys():\n",
        "    probabilities[label] = prior_probabilities[label]\n",
        "    for word in words:\n",
        "      probabilities [label] = conditional_probability (word, label)\n",
        "  return max(probabilities, key=probabilities.get), probabilities\n",
        "#Passo 5 Teste com um novo texto\n",
        "novo_texto = \"Eu amo resolver bugs\"\n",
        "classe, probs = predict(novo_texto)\n",
        "\n",
        "\n",
        "print(f'Texto: \"{novo_texto}\"')\n",
        "print(f'Classe prevista: {classe}')\n",
        "print(f'Probabilidades:')\n",
        "for label, prob in probs.items():\n",
        "  print(f\" {label}: {prob}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Passo 1 Importação das bibliotecas a serem utilizadas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "#Passo 2 Dados Exemplo\n",
        "corpus = [\n",
        "\"Eu amo PLN\", \"Eu odeio bugs\", \"Eu amo resolver problemas\", \"Odeio erros\", \"Amo programação\", \"Não gosto de falhas\"]\n",
        "classes = [\"negativo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\"]\n",
        "# Passo 3 Pre processamento e vetorização\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "y = classes\n",
        "#Passo 4 Dividir os dados e Treinar o modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "# Passo 5 Avaliar o modelo\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZu8AYgRUIyJ",
        "outputId": "b56db683-268e-4ece-a403-60bdd7b06bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      0.50      0.67         2\n",
            "    positivo       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.50      0.25      0.33         2\n",
            "weighted avg       1.00      0.50      0.67         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Importar Bibliotecas\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "#Baixar o dataset de exemplo nltk.download('movie_reviews\")\n",
        "from nltk.corpus import movie_reviews\n",
        "#2. Preparação dos dados\n",
        "#Coleta de textos e classes\n",
        "documents = [(\" \".join(movie_reviews.words(fileid)), category)\n",
        "            for category in movie_reviews.categories()\n",
        "            for fileid in movie_reviews.fileids (category)]\n",
        "\n",
        "#Separar textos e rótulos\n",
        "texts, labels = zip(*documents)\n",
        "\n",
        "#Transformar rótulos (positivo/negativo) em 0 e 1\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform (labels)\n",
        "#Dividir dados em treino e teste\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "#3. Representação do texto com TF-IDF\n",
        "#Criar o vetorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000) # Limitar a 5.080 palavras mais comuns\n",
        "#3. Representação do texto com TF-IDF\n",
        "#Criar o vetorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000) # Limitar a 5,000 palavras mais comuns\n",
        "\n",
        "#vectorizer = TfidfVectorizer(max_features=5000)\n",
        "#Cria um vetor TF-IDF, que transforma os textos em representações numéricas, atribuindo um peso a cada palavra com base na frequência no documento e em todo o corpus.\n",
        "#O parâmetro max_features=5000 limita o vocabulário às 5.000 palavras mais frequentes, ajudando a reduzir a dimensionalidade.\n",
        "\n",
        "\n",
        "#Ajustar e transformar os textos\n",
        "X_train = vectorizer.fit_transform(texts_train)\n",
        "X_test = vectorizer.transform(texts_test)\n",
        "\n",
        "#X_train = vectorizer.fit_transform(texts_train)\n",
        "#Ajusta o vetor TF-IDF aos textos de treinamento (texts_train) e os transforma em vetores numéricos, prontos para serem usados nos modelos.\n",
        "#X_test = vectorizer.transform(texts_test)\n",
        "\n",
        "#Transforma os textos de teste (texts_test) em vetores numéricos usando o mesmo modelo ajustado ao conjunto de treinamento, garantindo consistência.\n",
        "\n",
        "\n",
        "#4. Treinar os modelos\n",
        "#Treinamento do Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, labels_train)\n",
        "\n",
        "#nb_model = MultinomialNB()\n",
        "#Cria um modelo de Naive Bayes Multinomial, que é eficiente para dados textuais e trabalha bem com representações TF-IDF.\n",
        "#nb_model.fit(X_train, labels_train)\n",
        "\n",
        "#Treina o modelo Naive Bayes usando os vetores TF-IDF do conjunto de treinamento (X_train) e os rótulos correspondentes (labels_train).\n",
        "#nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Predição\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "#Usa o modelo treinado para prever os rótulos do conjunto de teste (X_test).\n",
        "\n",
        "#Treinamento do SVM\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, labels_train)\n",
        "\n",
        "#svm_model = SVC(kernel='linear')\n",
        "\n",
        "#Cria um modelo de Máquina de Vetores de Suporte (SVM) com kernel linear, adequado para classificação de texto.\n",
        "\n",
        "\n",
        "# Predição\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "#svm_model.fit(X_train, labels_train)\n",
        "\n",
        "#Treina o modelo SVM com os vetores TF-IDF do conjunto de treinamento (X_train) e os rótulos correspondentes (labels_train).\n",
        "#svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "#5. Avaliação\n",
        "#Avaliação do Naive Bayes\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "#Usa o modelo treinado SVM para prever os rótulos do conjunto de teste (X_test).\n",
        "#print(classification_report(...))\n",
        "\n",
        "#Avaliação do SVM\n",
        "print(\"SVM Performance:\")\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "#Avalia o desempenho de cada modelo, imprimindo um relatório de classificação, que inclui:\n",
        "#Precisão (precision): Proporção de predições corretas para uma classe específica.\n",
        "#Revocação (recall): Capacidade do modelo de encontrar todos os exemplos reais de uma classe.\n",
        "#F1-score: Média harmônica da precisão e revocação.\n",
        "#Suporte: Número de instâncias reais para cada classe.\n",
        "#O parâmetro target_names=label_encoder.classes_ exibe os nomes das classes ao invés de números, tornando o relatório mais interpretável.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hcIfYSwVY0f",
        "outputId": "4cfb4e32-e858-4e72-ef3d-481d29eb761c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    }
  ]
}